Task:请帮我写一个 Python 脚本，用于实现并测试一种面向 Edge GNN Inference 的轻量级图切分算法。我们需要对比“普通节点切分（Naive Node Partition）”和“基于 RC-M 的负载均衡切分（RC-M + Greedy Edge-Balanced Partition）”在切分速度和负载均衡度上的表现。Algorithm Description (The Proposed Method):这种方法是为了解决 Edge 端 GNN 推理时，Metis 开销过大以及 Power-law 分布导致的计算负载不均问题。Input: 一个稀疏图（Adjacency Matrix, CSR format），以及目标切分份数 $K$（例如 $K=5$）。Step 1: Reordering (Locality Optimization): 使用 Reverse Cuthill-McKee (RC-M) 算法对节点进行重排序，生成新的 Node ID 映射。这一步是为了减少切分后的 Halo Node 通信。Step 2: Target Calculation: 计算全图的总边数（Total Non-zeros, NNZ），计算 $Target = NNZ / K$。Step 3: Greedy Partitioning (Load Balancing):按照 RC-M 排序后的顺序遍历节点。维护一个累加器 current_edges。将当前节点的度数（Degree）加到 current_edges。当 current_edges 接近或超过 $Target$ 时，进行切分（记录 Cut Point），并将 current_edges 重置。重复直到切成 $K$ 份。Requirements for the Code:Data Generation: 使用 networkx 生成一个 Barabási-Albert (Power-law) 图来模拟真实场景（例如 $N=10000$ 节点，因为幂律分布下负载不均最明显）。Implementations:Baseline: Naive Equal-Node Partition (简单地把 N 个节点平均分成 K 份)。Proposed: The RC-M + Greedy Edge-Balanced Partition described above.Metrics to Report:Preprocessing Time: 算法运行的耗时（毫秒级）。Workload Balance (Standard Deviation of Edges): 统计 K 个 Subgraph 中，每个 Subgraph 实际包含的边数（Edges/NNZ），计算标准差。标准差越小说明负载越均衡。Libraries: 使用 scipy.sparse (for CSR matrix), scipy.sparse.csgraph (for RCM), networkx, numpy, time.